
@article{dunlosky_improving_2013,
	title = {Improving {Students}’ {Learning} {With} {Effective} {Learning} {Techniques}: {Promising} {Directions} {From} {Cognitive} and {Educational} {Psychology}},
	volume = {14},
	issn = {1529-1006, 1539-6053},
	url = {http://psi.sagepub.com/content/14/1/4},
	doi = {10.1177/1529100612453266},
	abstract = {Many students are being left behind by an educational system that some people believe is in crisis. Improving educational outcomes will require efforts on many fronts, but a central premise of this monograph is that one part of a solution involves helping students to better regulate their learning through the use of effective learning techniques. Fortunately, cognitive and educational psychologists have been developing and evaluating easy-to-use learning techniques that could help students achieve their learning goals. In this monograph, we discuss 10 learning techniques in detail and offer recommendations about their relative utility. We selected techniques that were expected to be relatively easy to use and hence could be adopted by many students. Also, some techniques (e.g., highlighting and rereading) were selected because students report relying heavily on them, which makes it especially important to examine how well they work. The techniques include elaborative interrogation, self-explanation, summarization, highlighting (or underlining), the keyword mnemonic, imagery use for text learning, rereading, practice testing, distributed practice, and interleaved practice.
To offer recommendations about the relative utility of these techniques, we evaluated whether their benefits generalize across four categories of variables: learning conditions, student characteristics, materials, and criterion tasks. Learning conditions include aspects of the learning environment in which the technique is implemented, such as whether a student studies alone or with a group. Student characteristics include variables such as age, ability, and level of prior knowledge. Materials vary from simple concepts to mathematical problems to complicated science texts. Criterion tasks include different outcome measures that are relevant to student achievement, such as those tapping memory, problem solving, and comprehension.
We attempted to provide thorough reviews for each technique, so this monograph is rather lengthy. However, we also wrote the monograph in a modular fashion, so it is easy to use. In particular, each review is divided into the following sections:
General description of the technique and why it should work How general are the effects of this technique? 2a. Learning conditions 2b. Student characteristics 2c. Materials 2d. Criterion tasks Effects in representative educational contexts Issues for implementation Overall assessment

The review for each technique can be read independently of the others, and particular variables of interest can be easily compared across techniques.
To foreshadow our final recommendations, the techniques vary widely with respect to their generalizability and promise for improving student learning. Practice testing and distributed practice received high utility assessments because they benefit learners of different ages and abilities and have been shown to boost students’ performance across many criterion tasks and even in educational contexts. Elaborative interrogation, self-explanation, and interleaved practice received moderate utility assessments. The benefits of these techniques do generalize across some variables, yet despite their promise, they fell short of a high utility assessment because the evidence for their efficacy is limited. For instance, elaborative interrogation and self-explanation have not been adequately evaluated in educational contexts, and the benefits of interleaving have just begun to be systematically explored, so the ultimate effectiveness of these techniques is currently unknown. Nevertheless, the techniques that received moderate-utility ratings show enough promise for us to recommend their use in appropriate situations, which we describe in detail within the review of each technique.
Five techniques received a low utility assessment: summarization, highlighting, the keyword mnemonic, imagery use for text learning, and rereading. These techniques were rated as low utility for numerous reasons. Summarization and imagery use for text learning have been shown to help some students on some criterion tasks, yet the conditions under which these techniques produce benefits are limited, and much research is still needed to fully explore their overall effectiveness. The keyword mnemonic is difficult to implement in some contexts, and it appears to benefit students for a limited number of materials and for short retention intervals. Most students report rereading and highlighting, yet these techniques do not consistently boost students’ performance, so other techniques should be used in their place (e.g., practice testing instead of rereading).
Our hope is that this monograph will foster improvements in student learning, not only by showcasing which learning techniques are likely to have the most generalizable effects but also by encouraging researchers to continue investigating the most promising techniques. Accordingly, in our closing remarks, we discuss some issues for how these techniques could be implemented by teachers and students, and we highlight directions for future research.},
	language = {en},
	number = {1},
	urldate = {2014-09-11},
	journal = {Psychological Science in the Public Interest},
	author = {Dunlosky, John and Rawson, Katherine A. and Marsh, Elizabeth J. and Nathan, Mitchell J. and Willingham, Daniel T.},
	month = jan,
	year = {2013},
	pages = {4--58}
}

@article{sun_peer_2014,
	title = {Peer assessment enhances student learning},
	url = {http://arxiv.org/abs/1410.3853},
	abstract = {Feedback has a powerful influence on learning, but it is also expensive to provide. In large classes, it may even be impossible for instructors to provide individualized feedback. Peer assessment has received attention lately as a way of providing personalized feedback that scales to large classes. Besides these obvious benefits, some researchers have also conjectured that students learn by peer assessing, although no studies have ever conclusively demonstrated this effect. By conducting a randomized controlled trial in an introductory statistics class, we provide evidence that peer assessment causes significant gains in student achievement. The strength of our conclusions depends critically on the careful design of the experiment, which was made possible by a web-based platform that we developed. Hence, our study is also a proof of concept of the high-quality experiments that are possible with online tools.},
	urldate = {2015-02-15},
	journal = {arXiv:1410.3853 [physics, stat]},
	author = {Sun, Dennis L. and Harris, Naftali and Walther, Guenther and Baiocchi, Michael},
	month = oct,
	year = {2014},
	note = {arXiv: 1410.3853}
}

@book{newport_deep_2016,
	title = {Deep {Work}: {Rules} for {Focused} {Success} in a {Distracted} {World}},
	url = {http://www.adlibris.com/se/bok/deep-work-9780349411903},
	abstract = {In 2012, Cal Newport coined the term "deep work" on his popular blog, Study Hacks, and began exploring the methods and mindset that foster a deep work practice. The concept quickly hit a nerve. Newport's articles on the topic have been read hundreds of thousands of times and were picked up and promoted by other bloggers and traditional media. Now, in DEEP WORK, Newport explains how to systematically train the mind to focus and reorganize our work lives so that deep work is at the core. He argues why this shift is crucial to stay ahead in a complex information economy. Put simply: developing and cultivating a deep work practice is one of the best decisions we can make in an increasingly distracted world.},
	urldate = {2016-01-26},
	publisher = {Piatkus Books},
	author = {Newport, Cal},
	month = jan,
	year = {2016}
}

@article{karpicke_retrieval_2011,
	title = {Retrieval {Practice} {Produces} {More} {Learning} than {Elaborative} {Studying} with {Concept} {Mapping}},
	volume = {331},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1199327},
	doi = {10.1126/science.1199327},
	language = {en},
	number = {6018},
	urldate = {2016-03-31},
	journal = {Science},
	author = {Karpicke, J. D. and Blunt, J. R.},
	month = feb,
	year = {2011},
	pages = {772--775}
}

@incollection{yu_misconceived_2006,
	address = {Lanham, Md},
	title = {Misconceived relationships between logical positivism and quantitative research},
	isbn = {978-0-7618-3429-8},
	abstract = {This book is a crystallization of author Chong Ho Yu's contemplation on the meaning of quantitative methods from the perspectives of history and the philosophy of science. Emphasizing the importance of a data analyst 'always knowing where the numbers come from,' Yu broadens the search to include a gamut of questions exploring the foundations of quantitative research. These questions include: How did the Fisherian and Pearsonian frameworks originate? Is quantitative methodology based upon logical positivism? How could statisticians synthesize abductive, deductive, and inductive methods while they are substantively different in their logics? How could researchers make a causal inference while a strong correlation does not necessarily entail a causal structure? This informative book is written for readers with an intermediate knowledge of statistics and philosophy.},
	booktitle = {Philosophical foundations of quantitative research methodology},
	publisher = {University Press of America},
	author = {Yu, Chong Ho},
	year = {2006},
	keywords = {viktig, läst}
}

@book{passer_psychology:_2008,
	address = {London},
	edition = {4},
	title = {Psychology: {The} {Science} of {Mind} and {Behavior}},
	isbn = {978-0-07-711836-5},
	shorttitle = {Psychology},
	abstract = {Michael w. Passer coordinates the introductory psychology program at the university of washington, which enrolls more than 3,000 students per year. He received his bachelors degree from the university of rochester, his ph.d. From ucla in social psychology, and has been a faculty member at the university of washington since 1977. A former danforth foundation fellow and u.w. Distinguished teaching award finalist, dr. Passer has had a career-long love of teaching. He teaches introductory psychology twice yearly and also has taught courses in research methods, social psychology, industrial-organizational psychology, and attribution theory. Dr. Passer developed and annually offers a graduate course on teaching of psychology, which prepares students for their careers in the college classroom. He has published over 20 scientific articles and chapters, primarily in the areas of attribution, stress, and anxiety.ronald e. Smith is professor of psychology at the university of washington, where he has served as director of clinical psychology training and as head of the social psychology and personality area. He received his bachelors degree from marquette university and his ph.d. From southern illinois university. Dr. Smith has held faculty positions at purdue university and at washington, as well as visiting appointments at marquette university, the university of hawaii, the university of new mexico, and ucla. His major research interests are in personality, stress and coping, and in performance enhancement research and intervention. Dr. Smith is a fellow of the american psychological association and a past president of the association for the advancement of applied sport psychology. He has published more than 100 scientific articles and book chapters in his areas of interest and has authored or co-authored 19 books on introductory psychology, stress and stress management, sport psychology, and human performance enhancement.},
	language = {English},
	publisher = {McGraw-Hill Higher Education},
	author = {Passer, Michael W.},
	month = nov,
	year = {2008}
}

@article{mazza_relearn_2016,
	title = {Relearn {Faster} and {Retain} {Longer} {Along} {With} {Practice}, {Sleep} {Makes} {Perfect}},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/early/2016/08/16/0956797616659930},
	doi = {10.1177/0956797616659930},
	abstract = {Both repeated practice and sleep improve long-term retention of information. The assumed common mechanism underlying these effects is memory reactivation, either on-line and effortful or off-line and effortless. In the study reported here, we investigated whether sleep-dependent memory consolidation could help to save practice time during relearning. During two sessions occurring 12 hr apart, 40 participants practiced foreign vocabulary until they reached a perfect level of performance. Half of them learned in the morning and relearned in the evening of a single day. The other half learned in the evening of one day, slept, and then relearned in the morning of the next day. Their retention was assessed 1 week later and 6 months later. We found that interleaving sleep between learning sessions not only reduced the amount of practice needed by half but also ensured much better long-term retention. Sleeping after learning is definitely a good strategy, but sleeping between two learning sessions is a better strategy.},
	language = {en},
	urldate = {2016-08-22},
	journal = {Psychological Science},
	author = {Mazza, Stéphanie and Gerbier, Emilie and Gustin, Marie-Paule and Kasikci, Zumrut and Koenig, Olivier and Toppino, Thomas C. and Magnin, Michel},
	month = aug,
	year = {2016},
	pmid = {27530500},
	pages = {0956797616659930}
}

@article{allwood_distinction_2012,
	title = {The distinction between qualitative and quantitative research methods is problematic},
	volume = {46},
	issn = {0033-5177, 1573-7845},
	url = {http://link.springer.com/10.1007/s11135-011-9455-8},
	doi = {10.1007/s11135-011-9455-8},
	language = {en},
	number = {5},
	urldate = {2016-10-05},
	journal = {Quality \& Quantity},
	author = {Allwood, Carl Martin},
	month = aug,
	year = {2012},
	keywords = {metod},
	pages = {1417--1429}
}

@article{mueller_pen_2014,
	title = {The {Pen} {Is} {Mightier} {Than} the {Keyboard}: {Advantages} of {Longhand} {Over} {Laptop} {Note} {Taking}},
	volume = {25},
	issn = {0956-7976},
	shorttitle = {The {Pen} {Is} {Mightier} {Than} the {Keyboard}},
	url = {http://dx.doi.org/10.1177/0956797614524581},
	doi = {10.1177/0956797614524581},
	abstract = {Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students’ capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers’ tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning.},
	language = {en},
	number = {6},
	urldate = {2017-02-20},
	journal = {Psychological Science},
	author = {Mueller, Pam A. and Oppenheimer, Daniel M.},
	month = jun,
	year = {2014},
	pages = {1159--1168}
}

@article{singer_reading_2017,
	title = {Reading {Across} {Mediums}: {Effects} of {Reading} {Digital} and {Print} {Texts} on {Comprehension} and {Calibration}},
	volume = {85},
	issn = {0022-0973},
	shorttitle = {Reading {Across} {Mediums}},
	url = {http://dx.doi.org/10.1080/00220973.2016.1143794},
	doi = {10.1080/00220973.2016.1143794},
	abstract = {This study explored differences that might exist in comprehension when students read digital and print texts. Ninety undergraduates read both digital and print versions of newspaper articles and book excerpts on topics of childhood ailments. Prior to reading texts in counterbalanced order, topic knowledge was assessed and students were asked to state medium preferences. After reading, students were asked to judge under which medium they comprehended best. Results demonstrated a clear preference for digital texts, and students typically predicted better comprehension when reading digitally. However, performance was not consistent with students' preferences and outcome predictions. While there were no differences across mediums when students identified the main idea of the text, students recalled key points linked to the main idea and other relevant information better when engaged with print. No differences in reading outcomes or calibration were found for newspaper or book excerpts.},
	number = {1},
	urldate = {2017-03-01},
	journal = {The Journal of Experimental Education},
	author = {Singer, Lauren M. and Alexander, Patricia A.},
	month = jan,
	year = {2017},
	pages = {155--172}
}

@article{patterson_computers_nodate,
	title = {Computers and {Productivity}: {Evidence} from {Laptop} {Use} in the {College} {Classroom}},
	issn = {0272-7757},
	shorttitle = {Computers and {Productivity}},
	url = {http://www.sciencedirect.com/science/article/pii/S0272775716307129},
	doi = {10.1016/j.econedurev.2017.02.004},
	abstract = {This paper evaluates the effect of classroom computer use on academic performance. Using a quasi-experimental design and administrative data, we find that computer use in college classrooms has a negative impact on course grades. Our study exploits institutional policies that generate plausibly random variation in laptop use within the classroom. Compared to students who are not affected by computer policies, students who are induced to use computers in class perform significantly worse and students who are influenced not to use computers perform significantly better. We find that the negative effects of computer use are concentrated among males and low-performing students and more prominent in quantitative courses.},
	urldate = {2017-03-09},
	journal = {Economics of Education Review},
	author = {Patterson, Richard W. and Patterson, Robert M.}
}

@article{zavala_solitary_2017,
	title = {Solitary {Discourse} {Is} a {Productive} {Activity}},
	issn = {0956-7976},
	url = {http://dx.doi.org/10.1177/0956797616689248},
	doi = {10.1177/0956797616689248},
	abstract = {Young adults received information regarding the platforms of two candidates for mayor of a troubled city. Half constructed a dialogue between advocates of the candidates, and the other half wrote an essay evaluating the candidates’ merits. Both groups then wrote a script for a TV spot favoring their preferred candidate. Results supported our hypothesis that the dialogic task would lead to deeper, more comprehensive processing of the two positions, and hence a richer representation of them. The TV scripts of the dialogue group included more references to city problems, candidates’ proposed actions, and links between them, as well as more criticisms of proposed actions and integrative judgments extending across multiple problems or proposed actions. Assessment of levels of epistemological understanding administered to the two groups after the writing tasks revealed that the dialogic group exhibited a lesser frequency of the absolutist position that knowledge consists of facts knowable with certainty. The potential of imagined interaction as a substitute for actual social exchange is considered.},
	language = {en},
	urldate = {2017-03-21},
	journal = {Psychological Science},
	author = {Zavala, Julia and Kuhn, Deanna},
	month = mar,
	year = {2017},
	pages = {0956797616689248}
}

@article{brown_grim_2016,
	title = {The {GRIM} {Test}: {A} {Simple} {Technique} {Detects} {Numerous} {Anomalies} in the {Reporting} of {Results} in {Psychology}},
	issn = {1948-5506, 1948-5514},
	shorttitle = {The {GRIM} {Test}},
	url = {http://journals.sagepub.com/doi/10.1177/1948550616673876},
	doi = {10.1177/1948550616673876},
	language = {en},
	urldate = {2017-04-18},
	journal = {Social Psychological and Personality Science},
	author = {Brown, Nicholas J. L. and Heathers, James A. J.},
	month = oct,
	year = {2016}
}

@book{dienes_understanding_2008,
	address = {New York},
	title = {Understanding psychology as a science: an introduction to scientific and statistical inference},
	isbn = {978-0-230-54230-3 978-0-230-54231-0},
	shorttitle = {Understanding psychology as a science},
	publisher = {Palgrave Macmillan},
	author = {Dienes, Zoltan},
	year = {2008},
	keywords = {metod, läst}
}

@article{ward_brain_2017,
	title = {Brain {Drain}: {The} {Mere} {Presence} of {One}’s {Own} {Smartphone} {Reduces} {Available} {Cognitive} {Capacity}},
	volume = {2},
	issn = {2378-1815},
	shorttitle = {Brain {Drain}},
	url = {http://www.journals.uchicago.edu/doi/10.1086/691462},
	doi = {10.1086/691462},
	abstract = {Our smartphones enable—and encourage—constant connection to information, entertainment, and each other. They put the world at our fingertips, and rarely leave our sides. Although these devices have immense potential to improve welfare, their persistent presence may come at a cognitive cost. In this research, we test the “brain drain” hypothesis that the mere presence of one’s own smartphone may occupy limited-capacity cognitive resources, thereby leaving fewer resources available for other tasks and undercutting cognitive performance. Results from two experiments indicate that even when people are successful at maintaining sustained attention—as when avoiding the temptation to check their phones—the mere presence of these devices reduces available cognitive capacity. Moreover, these cognitive costs are highest for those highest in smartphone dependence. We conclude by discussing the practical implications of this smartphone-induced brain drain for consumer decision-making and consumer welfare.},
	number = {2},
	journal = {Journal of the Association for Consumer Research},
	author = {Ward, Adrian F. and Duke, Kristen and Gneezy, Ayelet and Bos, Maarten W.},
	month = apr,
	year = {2017},
	keywords = {mobile},
	pages = {140--154}
}

@article{ravizza_logged_2017,
	title = {Logged {In} and {Zoned} {Out}},
	volume = {28},
	issn = {1467-9280},
	doi = {10.1177/0956797616677314},
	abstract = {Laptop computers are widely prevalent in university classrooms. Although laptops are a valuable tool, they offer access to a distracting temptation: the Internet. In the study reported here, we assessed the relationship between classroom performance and actual Internet usage for academic and nonacademic purposes. Students who were enrolled in an introductory psychology course logged into a proxy server that monitored their online activity during class. Past research relied on self-report, but the current methodology objectively measured time, frequency, and browsing history of participants' Internet usage. In addition, we assessed whether intelligence, motivation, and interest in course material could account for the relationship between Internet use and performance. Our results showed that nonacademic Internet use was common among students who brought laptops to class and was inversely related to class performance. This relationship was upheld after we accounted for motivation, interest, and intelligence. Class-related Internet use was not associated with a benefit to classroom performance.},
	language = {eng},
	number = {2},
	journal = {Psychological Science},
	author = {Ravizza, Susan M. and Uitvlugt, Mitchell G. and Fenn, Kimberly M.},
	month = feb,
	year = {2017},
	pmid = {28182528},
	pages = {171--180}
}

@article{meehl_theory-testing_1967,
	title = {Theory-{Testing} in {Psychology} and {Physics}: {A} {Methodological} {Paradox}},
	volume = {34},
	issn = {0031-8248},
	shorttitle = {Theory-{Testing} in {Psychology} and {Physics}},
	url = {http://www.jstor.org/stable/186099},
	doi = {10.2307/186099},
	abstract = {Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1/2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by "success" is very weak, and becomes weaker with increased precision. "Statistical significance" plays a logical role in psychology precisely the reverse of its role in physics. This problem is worsened by certain unhealthy tendencies prevalent among psychologists, such as a premium placed on experimental "cuteness" and a free reliance upon ad hoc explanations to avoid refutation.},
	number = {2},
	urldate = {2017-08-14},
	journal = {Philosophy of Science},
	author = {Meehl, Paul E.},
	year = {1967},
	keywords = {NHST, läs},
	pages = {103--115}
}

@incollection{malinas_simpsons_2016,
	edition = {Fall 2016},
	title = {Simpson's {Paradox}},
	url = {https://plato.stanford.edu/archives/fall2016/entries/paradox-simpson/},
	abstract = {Consider the following story:, While no capsul can be good for men and women, yet bad for people, orgood for people while being bad for men and women, the imagined data(see below) on which FIXIT based its recommendations exhibit patternsthat are both arithmetically possible and turn up in actual data sets.While there is nothing paradoxical about the existence of such datafrom the standpoint of arithmetic, they do pose problems for practicaldecision making (e.g., would you want to be treated with Fixit’scapsuls in light of the reported clinical trials?), for heuristicsused in intuitive reasoning about probabilities, for inferences fromdata to causal relations, and more generally, for philosophicalprograms that aim to eliminate or reduce causation to regularities andrelations between probabilities., The arithmetic, on which examples like FIXIT’s ill-judgedrecommendations are based, is unproblematic. In summary it is basedon the fact that, An association between a pair of variables can consistently beinverted in each subpopulation of a population when the population ispartitioned, and conversely, associations in each subpopulation can beinverted when data are aggregated., Call this principle Simpson’s Reversal of Inequalities. Failure torecognise such reversals can lead to the abovementioned pitfalls aboutwhat to do, what to believe, what to infer, and what causes what.Even when actual and possible reversals are recognized, pitfallsremain. On a positive note, once the possibilities of Simpson’sReversals are recognized, they provide a rich resource forconstructing causal models that help to explain many facts that appearat first to be anomolous. Moreover, there is a test called the“back-door criterion” (Pearl 1993) which can be used to helpresolve the question of whether one should base a decision on thestatistics from the aggregate population or from the partitionedsubpopulations., Section 1 provides a brief history of Simpson’s Paradox, a statementand diagnosis of the arithmetical structures that give rise to it, andthe boundary conditions for its occurrence. Section 2 examinespatterns of invalid reasoning that have their sources in Simpson’sParadox and possible ways of countering its effects. A particularlyimportant case where Simpson’s Paradox has been invalidly employed isdiscussed in Section 3. It has been mooted that paradoxical dataprovide counter-examples to the Sure Thing Principle in theories ofrational choice. Why such data appear to provide counter-examples tothe Sure Thing Principle is explained, and the appearance that they doso is dispelled. Section 4 discusses the roles and implications ofparadoxical data for theories of causal inference and for analyses ofcausal relations in terms of probabilities. While the conclusions ofthis section are largely negative, Section 5 illustrates howapparently paradoxical data can support causal models for theevolution of traits that at first appear to be incompatible with asetting in which natural selection disadvantages individuals thatexhibit the traits.},
	urldate = {2017-08-15},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Malinas, Gary and Bigelow, John},
	editor = {Zalta, Edward N.},
	year = {2016},
	keywords = {läst, SEP}
}

@book{royall_statistical_1997,
	address = {London, New York},
	edition = {1},
	series = {Monographs on statistics and applied probability},
	title = {Statistical evidence: a likelihood paradigm},
	isbn = {978-0-412-04411-3},
	shorttitle = {Statistical evidence},
	number = {71},
	publisher = {Chapman \& Hall},
	author = {Royall, Richard M.},
	year = {1997}
}

@techreport{anaya_grimmer_2016,
	title = {The {GRIMMER} test: {A} method for testing the validity of reported measures of variability},
	shorttitle = {The {GRIMMER} test},
	url = {https://peerj.com/preprints/2400v1/},
	abstract = {GRIMMER (Granularity-Related Inconsistency of Means Mapped to Error Repeats) builds upon the GRIM test and allows for testing whether reported measures of variability are mathematically possible. GRIMMER relies upon the statistical phenomenon that variances display a simple repetitive pattern when the data is discrete, i.e. granular. This observation allows for the generation of an algorithm that can quickly identify whether a reported statistic of any size or precision is consistent with the stated sample size and granularity. My implementation of the test is available at PrePubMed (http://www.prepubmed.org/grimmer) and currently allows for testing variances, standard deviations, and standard errors for integer data. It is possible to extend the test to other measures of variability such as deviation from the mean, or apply the test to non-integer data such as data reported to halves or tenths. The ability of the test to identify inconsistent statistics relies upon four factors: (1) the sample size; (2) the granularity of the data; (3) the precision (number of decimals) of the reported statistic; and (4) the size of the standard deviation or standard error (but not the variance). The test is most powerful when the sample size is small, the granularity is large, the statistic is reported to a large number of decimal places, and the standard deviation or standard error is small (variance is immune to size considerations). This test has important implications for any field that routinely reports statistics for granular data to at least two decimal places because it can help identify errors in publications, and should be used by journals during their initial screen of new submissions. The errors detected can be the result of anything from something as innocent as a typo or rounding error to large statistical mistakes or unfortunately even fraud. In this report I describe the mathematical foundations of the GRIMMER test and the algorithm I use to implement it.},
	language = {eng},
	urldate = {2017-09-02},
	institution = {PeerJ Preprints},
	author = {Anaya, Jordan},
	month = aug,
	year = {2016},
	note = {DOI: 10.7287/peerj.preprints.2400v1}
}


@article{carter_impact_2017,
	title = {The impact of computer usage on academic performance: {Evidence} from a randomized trial at the {United} {States} {Military} {Academy}},
	volume = {56},
	issn = {0272-7757},
	shorttitle = {The impact of computer usage on academic performance},
	url = {http://www.sciencedirect.com/science/article/pii/S0272775716303454},
	doi = {10.1016/j.econedurev.2016.12.005},
	abstract = {We present findings from a study that prohibited computer devices in randomly selected classrooms of an introductory economics course at the United States Military Academy. Average final exam scores among students assigned to classrooms that allowed computers were 0.18 standard deviations lower than exam scores of students in classrooms that prohibited computers. Through the use of two separate treatment arms, we uncover evidence that this negative effect occurs in classrooms where laptops and tablets are permitted without restriction and in classrooms where students are only permitted to use tablets that must remain flat on the desk.},
	number = {Supplement C},
	urldate = {2017-11-23},
	journal = {Economics of Education Review},
	author = {Carter, Susan Payne and Greenberg, Kyle and Walker, Michael S.},
	month = feb,
	year = {2017},
	pages = {118--132}
}

@article{sana_laptop_2013,
	title = {Laptop multitasking hinders classroom learning for both users and nearby peers},
	volume = {62},
	issn = {0360-1315},
	url = {http://www.sciencedirect.com/science/article/pii/S0360131512002254},
	doi = {10.1016/j.compedu.2012.10.003},
	abstract = {Laptops are commonplace in university classrooms. In light of cognitive psychology theory on costs associated with multitasking, we examined the effects of in-class laptop use on student learning in a simulated classroom. We found that participants who multitasked on a laptop during a lecture scored lower on a test compared to those who did not multitask, and participants who were in direct view of a multitasking peer scored lower on a test compared to those who were not. The results demonstrate that multitasking on a laptop poses a significant distraction to both users and fellow students and can be detrimental to comprehension of lecture content.},
	number = {Supplement C},
	urldate = {2017-11-23},
	journal = {Computers \& Education},
	author = {Sana, Faria and Weston, Tina and Cepeda, Nicholas J.},
	month = mar,
	year = {2013},
	pages = {24--31}
}

@article{neyman_outline_1937,
	title = {Outline of a {Theory} of {Statistical} {Estimation} {Based} on the {Classical} {Theory} of {Probability}},
	volume = {236},
	issn = {0080-4614},
	number = {767},
	urldate = {2017-02-10},
	journal = {Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences},
	author = {Neyman, J.},
	year = {1937},
	keywords = {metod, NHST},
	pages = {333--380}
}

@article{meehl_theoretical_1978,
	title = {Theoretical risks and tabular asterisks: {Sir} {Karl}, {Sir} {Ronald}, and the slow progress of soft psychology.},
	volume = {46},
	issn = {0022-006X},
	shorttitle = {Theoretical risks and tabular asterisks},
	url = {http://content.apa.org/journals/ccp/46/4/806},
	doi = {10.1037/0022-006X.46.4.806},
	abstract = {Theories in "soft" areas of psychology lack the cumulative character of scientific knowledge. They tend neither to be refuted nor corroborated, but instead merely fade away as people lose interest. Even though intrinsic subject matter difficulties (20 listed) contribute to this, the excessive reliance on significance testing is partly responsible, being a poor way of doing science. Karl Popper's approach, with modifications, would be prophylactic. Since the null hypothesis is quasialways false, tables summarizing research in terms of patterns of "significant differences" are little more than complex, causally uninterpretable outcomes of statistical power functions. Multiple paths to estimating numerical point values ("consistency tests") are better, even if approximate with rough tolerances; and lacking this, ranges, orderings, second-order differences, curve peaks and valleys, and function forms should be used. Such methods are usual in developed sciences that seldom report statistical significance. Consistency tests of a conjectural taxometric model yielded 94\% success with zero false negatives.},
	language = {en},
	number = {4},
	urldate = {2017-09-29},
	journal = {Journal of Consulting and Clinical Psychology},
	author = {Meehl, Paul E.},
	year = {1978},
	keywords = {läs},
	pages = {806--834}
}


@article{rosnow_statistical_1989,
	title = {Statistical procedures and the justification of knowledge in psychological science},
	volume = {44},
	copyright = {(c) 2016 APA, all rights reserved},
	issn = {1935-990X 0003-066X},
	doi = {10.1037/0003-066X.44.10.1276},
	abstract = {Justification, in the vernacular language of philosophy of science, refers to the evaluation, defense, and confirmation of claims of truth. In this article, we examine some aspects of the rhetoric of justification, which in part draws on statistical data analysis to shore up facts and inductive inferences. There are a number of problems of methodological spirit and substance that in the past have been resistant to attempts to correct them. The major problems are discussed, and readers are reminded of ways to clear away these obstacles to justification.},
	language = {English},
	number = {10},
	journal = {American Psychologist},
	author = {Rosnow, Ralph L. and Rosenthal, Robert},
	year = {1989},
	keywords = {NHST, metod},
	pages = {1276--1284}
}


@article{silberzahn_many_2017,
	title = {Many analysts, one dataset: {Making} transparent how variations in analytical choices affect results},
	shorttitle = {Many analysts, one dataset},
	url = {https://psyarxiv.com/qkwst/},
	doi = {10.17605/OSF.IO/QKWST},
	abstract = {Twenty-nine teams involving 61 analysts used the same dataset to address the same research question: whether soccer referees are more likely to give red cards to dark skin toned players than light skin toned players. Analytic approaches varied widely across teams, and estimated effect sizes ranged from 0.89 to 2.93 in odds ratio units, with a median of 1.31. Twenty teams (69\%) found a statistically significant positive effect and nine teams (31\%) observed a non-significant relationship. Overall 29 different analyses used 21 unique combinations of covariates. We found that neither analysts' prior beliefs about the effect, nor their level of expertise, nor peer-reviewed quality of analysis readily explained variation in analysis outcomes. This suggests that significant variation in analysis of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy by which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective analytic choices influence research results.},
	urldate = {2017-10-01},
	journal = {PsyArXiv},
	author = {Silberzahn, Raphael and Uhlmann, Eric Luis and Martin, Dan and Anselmi, Pasquale and Aust, Frederik and Awtrey, Eli C. and Bahník, Štěpán and Bai, Feng and Bannard, Colin and Bonnier, Evelina and Carlsson, Rickard and Cheung, Felix and Christensen, Garret and Clay, Russ and Craig, Maureen A. and Rosa, Anna Dalla and Dam, Lammertjan and Evans, Mathew H. and Cervantes, Ismael Flores and Fong, Nathan and Gamez-Djokic, Monica and Glenz, Andreas and Gordon-McKeon, Shauna and Heaton, Tim and Eriksson, Karin Hederos and Heene, Moritz and Mohr, Alicia Hofelich and Högden, Fabia and Hui, Kent and Johannesson, Magnus and Kalodimos, Jonathan and Kaszubowski, Erikson and Kennedy, Deanna and Lei, Ryan and Lindsay, Thomas Andrew and Liverani, Silvia and Madan, Christopher and Molden, Daniel C. and Molleman, Eric and Morey, Richard D. and Mulder, Laetitia and Nijstad, Bernard A. and Pope, Bryson and Pope, Nolan and Prenoveau, Jason M. and Rink, Floor and Robusto, Egidio and Roderique, Hadiya and Sandberg, Anna and Schlueter, Elmar and S, Felix and Sherman, Martin F. and Sommer, S. Amy and Sotak, Kristin Lee and Spain, Seth M. and Spörlein, Christoph and Stafford, Tom and Stefanutti, Luca and Täuber, Susanne and Ullrich, Johannes and Vianello, Michelangelo and Wagenmakers, Eric-Jan and Witkowiak, Maciej and Yoon, Sangsuk and Nosek, Brian A.},
	month = apr,
	year = {2017}
}

@book{shadish_experimental_2001,
	address = {Boston},
	edition = {2},
	title = {Experimental and quasi-experimental designs for generalized causal inference},
	isbn = {978-0-395-61556-0},
	abstract = {This long awaited successor of the original Cook/Campbell Quasi-Experimentation: Design and Analysis Issues for Field Settings represents updates in the field over the last two decades. The book covers four major topics in field experimentation:},
	publisher = {Houghton Mifflin},
	author = {Shadish, William R. and Cook, Thomas D. and Campbell, Donald T.},
	year = {2001},
	keywords = {experiment, metod}
}


@article{gelman_difference_2006,
	title = {The {Difference} {Between} “{Significant}” and “{Not} {Significant}” is not {Itself} {Statistically} {Significant}},
	volume = {60},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
	doi = {10.1198/000313006X152649},
	language = {en},
	number = {4},
	urldate = {2016-03-08},
	journal = {The American Statistician},
	author = {Gelman, Andrew and Stern, Hal},
	month = nov,
	year = {2006},
	keywords = {NHST},
	pages = {328--331}
}

@article{schoenfeld_is_2012,
	title = {Is everything we eat associated with cancer? {A} systematic cookbook review},
	issn = {0002-9165, 1938-3207},
	shorttitle = {Is everything we eat associated with cancer?},
	url = {http://ajcn.nutrition.org/content/early/2012/11/27/ajcn.112.047142},
	doi = {10.3945/ajcn.112.047142},
	language = {en},
	urldate = {2017-01-04},
	journal = {The American Journal of Clinical Nutrition},
	author = {Schoenfeld, Jonathan D. and Ioannidis, John PA},
	month = dec,
	year = {2012},
	pmid = {23193004},
	keywords = {reviews}
}

@article{richard_one_2003,
	title = {One {Hundred} {Years} of {Social} {Psychology} {Quantitatively} {Described}.},
	volume = {7},
	issn = {1939-1552, 1089-2680},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1089-2680.7.4.331},
	doi = {10.1037/1089-2680.7.4.331},
	language = {en},
	number = {4},
	urldate = {2016-12-10},
	journal = {Review of General Psychology},
	author = {Richard, F. D. and Bond, Charles F. and Stokes-Zoota, Juli J.},
	year = {2003},
	keywords = {reviews, viktig, meta-analysis},
	pages = {331--363}
}

@article{rains_sixty_2018,
	title = {Sixty years of quantitative communication research summarized: lessons from 149 meta-analyses},
	volume = {0},
	issn = {2380-8985},
	shorttitle = {Sixty years of quantitative communication research summarized},
	url = {https://doi.org/10.1080/23808985.2018.1446350},
	doi = {10.1080/23808985.2018.1446350},
	abstract = {In an effort to better understand the state of knowledge production in the field of Communication, we examine the results of 149 meta-analyses exploring human communication phenomena. The meta-analyses summarize more than 60 years of quantitative research involving more than 8 million participants. The mean effect estimate is r = .21, and three-quarters of the meta-analyses reported an estimate of less than r = .29. Several trends in the findings from the meta-analyses are examined. The results underscore the notion that communication is a complex and highly contingent phenomenon and highlight some specific instances in which communication variables and processes produce (in)substantial effects. Taken as a whole, this project offers insights about the status of quantitative communication research and the collective efforts of scholars working in our discipline.},
	number = {0},
	urldate = {2018-03-15},
	journal = {Annals of the International Communication Association},
	author = {Rains, Stephen A. and Levine, Timothy R. and Weber, Rene},
	month = mar,
	year = {2018},
	pages = {1--20}
}

@book{cohen_statistical_1988,
	address = {Hillsdale, N.J},
	edition = {2},
	title = {Statistical {Power} {Analysis} for the {Behavioral} {Sciences}},
	isbn = {978-0-8058-0283-2},
	abstract = {Statistical Power Analysis is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The Second Edition includes:  * a chapter covering power analysis in set correlation and multivariate methods; * a chapter considering effect size, psychometric reliability, and the efficacy of "qualifying" dependent variables and; * expanded power and sample size tables for multiple regression/correlation.},
	language = {English},
	publisher = {Routledge},
	author = {Cohen, Jacob},
	month = jul,
	year = {1988},
	keywords = {NHST, metod}
}

@article{wammes_drawing_2016,
	title = {The drawing effect: {Evidence} for reliable and robust memory benefits in free recall},
	volume = {69},
	issn = {1747-0218},
	shorttitle = {The drawing effect},
	url = {https://doi.org/10.1080/17470218.2015.1094494},
	doi = {10.1080/17470218.2015.1094494},
	abstract = {In 7 free-recall experiments, the benefit of creating drawings of to-be-remembered information relative to writing was examined as a mnemonic strategy. In Experiments 1 and 2, participants were presented with a list of words and were asked to either draw or write out each. Drawn words were better recalled than written. Experiments 3–5 showed that the memory boost provided by drawing could not be explained by elaborative encoding (deep level of processing, LoP), visual imagery, or picture superiority, respectively. In Experiment 6, we explored potential limitations of the drawing effect, by reducing encoding time and increasing list length. Drawing, relative to writing, still benefited memory despite these constraints. In Experiment 7, the drawing effect was significant even when encoding trial types were compared in pure lists between participants, inconsistent with a distinctiveness account. Together these experiments indicate that drawing enhances memory relative to writing, across settings, instructions, and alternate encoding strategies, both within- and between-participants, and that a deep LoP, visual imagery, or picture superiority, alone or collectively, are not sufficient to explain the observed effect. We propose that drawing improves memory by encouraging a seamless integration of semantic, visual, and motor aspects of a memory trace.},
	number = {9},
	urldate = {2018-11-24},
	journal = {The Quarterly Journal of Experimental Psychology},
	author = {Wammes, Jeffrey D. and Meade, Melissa E. and Fernandes, Myra A.},
	month = sep,
	year = {2016},
	pmid = {26444654},
	pages = {1752--1776},
	file = {Wammes et al (2016) The drawing effect.pdf:C\:\\Users\\Peter\\Zotero\\storage\\PIIJV7HX\\Wammes et al (2016) The drawing effect.pdf:application/pdf}
}

@article{martin_re-watching_2018,
	title = {Re-watching lectures as a study strategy and its effect on mind wandering},
	volume = {65},
	issn = {2190-5142(Electronic),1618-3169(Print)},
	doi = {10.1027/1618-3169/a000412},
	abstract = {Material re-exposure (e.g., re-reading) is a popular mnemonic strategy, however, its utility has been questioned. We extend research on re-reading to re-watching – an emerging mnemonic technique given the increased use of recorded lectures today (e.g., in online courses). Consistent with findings from recent investigations of re-reading, there were no benefits of massed re-watching on memory for lecture material and re-watching increased rates of mind wandering. We discuss implications for understanding the cognitive consequences of re-exposure-based mnemonics.},
	number = {5},
	journal = {Experimental Psychology},
	author = {Martin, Leonardo and Mills, Caitlin and D'Mello, Sidney K. and Risko, Evan F.},
	year = {2018},
	pages = {297--305}
}

@article{carver_case_1978,
	title = {The {Case} against {Statistical} {Significance} {Testing}},
	volume = {48},
	abstract = {Reviews case against using traditional statistical methods in educational research. Examines "fantasies" entertained by researchers about the meaning of statistical significance. Recommends abandoning statistical significance testing and suggests other ways of evaluating research results. Advocates a return to the scientific method of examining data and replicating results. (Author/CSS)},
	language = {en},
	number = {3},
	urldate = {2018-12-30},
	journal = {Harvard Educational Review},
	author = {Carver, Ronald P.},
	year = {1978},
	keywords = {NHST},
	pages = {378--99}
}